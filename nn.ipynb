{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5b4933e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"clean_weather.csv\", index_col=0)\n",
    "data = data.ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a54069c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nishan/Downloads/nn_scratch/.venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "PREDICTORS = [\"tmax\", \"tmin\", \"rain\"]\n",
    "TARGET = \"tmax_tomorrow\"\n",
    "\n",
    "# Scale our data so relu works better\n",
    "# All temperature values in the original dataset are over 0, so relu won't do much for several epochs\n",
    "# Scaling will make some of the input data negative\n",
    "scaler = StandardScaler()\n",
    "data[PREDICTORS] = scaler.fit_transform(data[PREDICTORS])\n",
    "\n",
    "split_data = np.split(data, [int(.7 * len(data)), int(.85 * len(data))])\n",
    "(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = [[d[PREDICTORS].to_numpy(), d[[TARGET]].to_numpy()] for d in split_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "613a528b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_layers(inputs):\n",
    "  layers = []\n",
    "  for i in range(1, len(inputs)):\n",
    "    layers.append([\n",
    "      np.random.rand(inputs[i-1], inputs[i]) / 5 -.1,\n",
    "      np.ones((1, inputs[i]))\n",
    "    ])\n",
    "  \n",
    "  return layers\n",
    "\n",
    "layers_conf = [3, 10, 10, 1]\n",
    "\n",
    "layers = init_layers(layers_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72e13d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(batch, layers):\n",
    "  hiddens = [batch.copy()]\n",
    "  for i in range(len(layers)):\n",
    "    batch = np.matmul(batch, layers[i][0]) + layers[i][1]\n",
    "    if i < len(layers) -1:\n",
    "      batch = np.maximum(batch, 0)\n",
    "    hiddens.append(batch.copy())\n",
    "  return batch, hiddens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4752f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(actual, predicted):\n",
    "  return (actual - predicted) ** 2\n",
    "\n",
    "def mse_grad(actual, predicted):\n",
    "  return predicted - actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d71a3276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(layers, hidden, grad, lr):\n",
    "    for i in range(len(layers)-1, -1, -1):\n",
    "      if i != len(layers) - 1:\n",
    "        grad = np.multiply(grad, np.heaviside(hidden[i+1], 0))\n",
    "\n",
    "      w_grad = hidden[i].T @ grad\n",
    "      b_grad = np.mean(grad, axis=0)\n",
    "\n",
    "      layers[i][0] -= w_grad * lr\n",
    "      layers[i][1] -= b_grad * lr\n",
    "        \n",
    "      grad = grad @ layers[i][0].T\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5435b631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train MSE: 3346.419652661795 Valid MSE: 1793.6336011311687\n",
      "Epoch: 1 Train MSE: 375.33071223010023 Valid MSE: 26.41047662451915\n",
      "Epoch: 2 Train MSE: 23.35240154063674 Valid MSE: 21.31667160684363\n",
      "Epoch: 3 Train MSE: 22.439479552567846 Valid MSE: 20.85441433295814\n",
      "Epoch: 4 Train MSE: 22.178367842392767 Valid MSE: 20.760556053582338\n",
      "Epoch: 5 Train MSE: 22.11068383487087 Valid MSE: 20.745627473547604\n",
      "Epoch: 6 Train MSE: 22.091457360828787 Valid MSE: 20.74549406393329\n",
      "Epoch: 7 Train MSE: 22.08459319796934 Valid MSE: 20.7469135328254\n",
      "Epoch: 8 Train MSE: 22.080952319959565 Valid MSE: 20.747276248984548\n",
      "Epoch: 9 Train MSE: 22.078354440963075 Valid MSE: 20.74700814721253\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "\n",
    "lr = 1e-6\n",
    "epochs=10\n",
    "batch_size = 8\n",
    "\n",
    "layers = init_layers(layers_conf)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = []\n",
    "\n",
    "    for i in range(0, train_x.shape[0], batch_size):\n",
    "        x_batch = train_x[i:(i+batch_size)]\n",
    "        y_batch = train_y[i:(i+batch_size)]\n",
    "        pred, hidden = forward(x_batch, layers)\n",
    "\n",
    "        loss = mse_grad(y_batch, pred)\n",
    "        epoch_loss.append(np.mean(loss ** 2))\n",
    "\n",
    "        layers = backward(layers, hidden, loss, lr)\n",
    "\n",
    "\n",
    "    valid_preds, _ = forward(valid_x, layers)\n",
    "\n",
    "    print(f\"Epoch: {epoch} Train MSE: {mean(epoch_loss)} Valid MSE: {np.mean(mse(valid_preds,valid_y))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
